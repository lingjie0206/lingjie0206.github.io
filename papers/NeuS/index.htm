<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<title>NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction </title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


	<!-- Meta tags for Zotero grab citation -->
	<meta name="citation_title" content="NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction">
	<meta name="citation_author" content="Wang, Peng">
	<meta name="citation_author" content="Liu, Lingjie">
	
	<meta name="citation_author" content="Liu, Yuan">
	<meta name="citation_author" content="Theobalt, Christian">
	<meta name="citation_author" content="Komura, Taku">
	<meta name="citation_author" content="Wang, Wenping">
	<meta name="citation_publication_date" content="2021">
	<meta name="citation_conference_title" content="arxiv">
	<meta name="citation_pdf_url" content="https://arxiv.org/pdf/2007.11571.pdf">

	<meta name="robots" content="index,follow">
	<meta name="description"
		content="
		We present a novel neural surface reconstruction method,  called {\em NeuS}, for reconstructing objects and scenes with high fidelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR [Niemeyer et al, 2020] and IDR [Yariv et al., 2020], require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures.  Meanwhile, recent neural methods for novel view synthesis, such as NeRF [Mildenhall et al., 2020] and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difficult because there are not sufficient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a {\em signed distance function} (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the first order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion.">
	<link rel="author" href="https://lingjie0206.github.io/" />


	<!-- Fonts and stuff -->
	<link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800'
		rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" href="css/project.css" media="screen" />
	<link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />
	<script src="js/google-code-prettify/prettify.js"></script>
</head>

<body>
	<div id="content">
		<div id="content-inner">
			<div class="section logos" style="text-align:center">
				<a href="https://www.hku.hk/" target="_blank"><IMG src="./logos/hku_logo.jpg" height="35" border="0"></a>
				</td>
				<a href="http://www.mpi-inf.mpg.de/home/" target="_blank"><IMG src="./logos/Logo_MPII.png" height="35"
						border="0"></a></td>
				<a href="/index.html" target="_blank"><IMG src="./logos/Logo_gvv.png" height="35" border="0"></a></td>
				
				<a href="https://www.tamu.edu/" target="_blank"><IMG src="./logos/Texas-AM-University_logo.jpg" height="35"="0"></a></td>
			</div>

			<div class="section head">

				<h1>NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction</h1>

				<div class="authors">
					<a href="https://totoro97.github.io/about.html" target="_blank">Peng Wang</a><sup> 1</sup>&#160;&#160;
					<a href="https://lingjie0206.github.io/" target="_blank">Lingjie Liu</a><sup> 2</sup>&#160;&#160;
					<a href="https://liuyuan-pal.github.io/" target="_blank">Yuan Liu</a><sup> 1</sup>&#160;&#160;
					
					<a href="http://people.mpi-inf.mpg.de/~theobalt/" target="_blank">Christian Theobalt</a><sup>
						2</sup>&#160;&#160;
					<a href="https://www.cs.hku.hk/index.php/people/academic-staff/taku">Taku Komura</a><sup> 1</sup>&#160;&#160;
					<a href="https://www.cs.hku.hk/people/academic-staff/wenping">Wenping Wang</a><sup> 1,3</sup>&#160;&#160;
				</div>

				<div class="affiliations">
					<sup>1</sup><a href="https://www.hku.hk/" target="_blank">University of Hong Kong</a>&#160;&#160;
					<sup>2</sup><a href="http://www.mpi-inf.mpg.de/home/" target="_blank">MPI Informatics, Saarland
						Informatics Campus</a>&#160;&#160;
					<sup>3</sup><a href="https://www.tamu.edu/" target="_blank">Texas A&M University</a>&#160;&#160;
				</div>
				<div class="venue">NeurIPS 2021 (Spotlight) </div>

				<div class="section downloads">
					<!--<h2>Downloads</h2>-->
					<center>
						<ul>
							<li class="grid">
								<div class="griditem">
									<a href="https://arxiv.org/abs/2106.10689" target="_blank"
										class="imageLink"><img src="images/pdf.png"></a><br />
									<a href="https://arxiv.org/abs/2106.10689">Paper (41 MB)</a>
								</div>
							</li>
							<li class="grid">
								<div class="griditem">
									<img src="images/data_ico.png"><br />
									<a href="https://github.com/Totoro97/NeuS">Code & Data</a>

								</div>
							</li>
						</ul>
					</center>
				</div>
			</div>




			<div class="section abstract">
				<h2>Abstract</h2><br>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="abs_f.jpg" style="width:80%; margin-bottom:20px">

					</div>

				</div>
				<p>
					We present a novel neural surface reconstruction method,  called NeuS (pronunciation: /nuÀêz/, same as "news"), for reconstructing objects and scenes with high fidelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR [Niemeyer et al, 2020] and IDR [Yariv et al., 2020], require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures.  Meanwhile, recent neural methods for novel view synthesis, such as NeRF [Mildenhall et al., 2020] and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difficult because there are not sufficient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a signed distance function (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the first order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion.</p>
				</p>
			</div>

			<!--<div class="section abstract">
				<h2>Full Video</h2><br>
				<center>
					<!-- <iframe width="640" height="360" src="data/video.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<!--<iframe width="640" height="360" src="https://www.youtube.com/embed/RFqPwH7QFEI" frameborder="0"
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
						allowfullscreen></iframe>-->
					<!--iframe src="./data/video.mp4" allow="autoplay; encrypted-media" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" width="560" height="315" frameborder="0"></iframe-->
					<!--<p style="font-size:11px; text-align:center">
					Download Video: <a href="data/video.mp4" target="_blank">HD</a> (MP4, 111 MB)
				</p>
				</center>
			</div>-->

			<div class="section abstract">
				<h2>Introduction</h2>
				
				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/intro1.mp4" type="video/mp4">
					</video>
				</center>
				<p>Given a set of posed 2D images of a 3D object, our goal is to reconstruct the surface of the object. The surface is represented by the zero-level set of an implicit signed distance function (SDF) encoded by a fully connected neural network (MLP). In order to learn the weights of this network, we developed a novel volume rendering method to render images from the implicit SDF and minimize the difference between the rendered images and the input images. This volume rendering approach ensures robust optimization in NeuS for reconstructing objects of complex structures. </p>

				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/intro2.mp4" type="video/mp4">
					</video>
				</center>

				<p>Our method is able to accurately reconstruct thin structures, especially on the edges with abrupt depth changes.
				</p>
			</div>

			<div class="section abstract">
				<h2>Comparisons (w/o mask supervision)</h2><br>
				
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
					
					 <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/compare3.mp4" type="video/mp4">
					</video>
					<h3>Scan 69 from the DTU dataset</h3><br>
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/compare4.mp4" type="video/mp4">
					</video>
					<h3>Statue from the BlendedMVS dataset</h3><br>
					</div>

				</div>
			</div>
			
			<div class="section abstract">
				<h2>Comparisons (w/ mask supervision)</h2><br>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
					 <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/compare1.mp4" type="video/mp4">
					</video>
					<h3>Scan 37 from the DTU dataset</h3><br>
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/compare2.mp4" type="video/mp4">
					</video>
					<h3>Stone from the BlendedMVS dataset</h3><br>
					</div>

				</div>
			</div>
			

			<div class="section abstract">
				<h2>More Results of NeuS (w/o mask supervision)</h2><br>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
					 <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/more_results.mp4" type="video/mp4">
					</video>
					<h3>Scenes from the DTU dataset</h3><br>
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/more_results2.mp4" type="video/mp4">
					</video>
					<h3>Scenes from the BlendedMVS dataset</h3><br>
				</div>
			</div>			
	
			<div class="section list">
				<h2>Citation</h2>
				<div class="section bibtex">
					<pre>
@article{wang2021neus,
      title={NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction}, 
      author={Peng Wang and Lingjie Liu and Yuan Liu and Christian Theobalt and Taku Komura and Wenping Wang},
	  journal={NeurIPS},
      year={2021}
}
				</div>
			</div>
			
			<div class="section list">
				<h2>Related Links</h2>
				<div class="row" style="margin-top:15px">
				<li>Parts of <a href="https://github.com/Totoro97/NeuS" target="_blank">our PyTorch implementation</a> are taken from <a href="https://github.com/lioryariv/idr" target="_blank">IDR</a> and <a href="https://github.com/yenchenlin/nerf-pytorch" target="_blank">NeRF-pytorch</a>.
				<li>Check the concurrent works of learning neural implicit surfaces: </br> 			
				&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<a href="https://arxiv.org/abs/2104.10078" target="_blank">UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction</a>, Oechsle et al. 2021 </br>
				&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<a href="https://arxiv.org/abs/2106.12052" target="_blank">Volume Rendering of Neural Implicit Surfaces</a>, Yariv et al. 2021 
				<li>Also check other works about neural scene representations and neural rendering from our group: </br> 
				&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<a href="https://lingjie0206.github.io/papers/NSVF/" target="_blank">Neural Sparse Voxel Fields:</a>, Liu et al. 2020 </br> 	
				&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/" target="_blank">Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Dynamic Scene From Monocular Video</a>, Tretschk et al. 2021</br> 	
				&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<a href="http://gvv.mpi-inf.mpg.de/projects/NeuralActor/" target="_blank">Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control</a>, Liu et al. 2021 </br> 	
				&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<a href="https://liuyuan-pal.github.io/NeuRay/" target="_blank">Neural Rays for Occlusion-aware Image-based Rendering</a>, Liu et al. 2021. </br> 	
				</div>
			</div>
			
			<div class="section list">
				<h2>Acknowledgements</h2>
				<div class="row" style="margin-top:15px">
				<p>We thank Michael Oechsle for providing the results of UNISURF. Christian Theobalt was supported by ERC Consolidator Grant 770784. Lingjie Liu was supported by Lise Meitner Postdoctoral Fellowship.</p> 
				</div>
			</div>
			
			
			<div class="section">
				<hr class="smooth">
				This page is <a href="http://www.zotero.org" target="_blank">Zotero</a> translator friendly. Page last updated 
				<script type="text/javascript">
					var m = "This page was last updated: " + document.lastModified;
					var p = m.length - 9;
					document.writeln("<left>");
					document.write(m.substring(p, 0) + ".");
					document.writeln("</left>");
				</script>
				<a href="https://www.mpi-inf.mpg.de/imprint/">Imprint</a>. <a href="https://data-protection.mpi-klsb.mpg.de/inf/gvv.mpi-inf.mpg.de/projects/">Data Protection</a>.
			</div>
		</div>
	</div>
</body>
</html>