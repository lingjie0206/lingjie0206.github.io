<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<title>Neural Sparse Voxel Fields </title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


	<!-- Meta tags for Zotero grab citation -->
	<meta name="citation_title" content="Neural Sparse Voxel Fields">
	<meta name="citation_author" content="Liu, Lingjie">
	<meta name="citation_author" content="Gu, Jiatao">
	<meta name="citation_author" content="Lin, Kyaw Zaw">
	<meta name="citation_author" content="Chua, Tat-Seng">
	<meta name="citation_author" content="Theobalt, Christian">
	<meta name="citation_publication_date" content="2020">
	<meta name="citation_conference_title" content="NeurIPS">
	<meta name="citation_pdf_url" content="https://arxiv.org/pdf/2007.11571.pdf">

	<meta name="robots" content="index,follow">
	<meta name="description"
		content="
		Photo-realistic free-viewpoint rendering of real-world scenes using classical computer graphics techniques is challenging, because it requires the difficult step of capturing detailed appearance and geometry models. Recent studies have demonstrated promising results by learning scene representations that implicitly encode both geometry and appearance without 3D supervision. However, existing approaches in practice often show blurry renderings caused by the limited network capacity or the difficulty in finding accurate intersections of camera rays with the scene geometry. Synthesizing high-resolution imagery from these representations often requires time-consuming optical ray marching. In this work, we introduce Neural Sparse Voxel Fields (NSVF), a new neural scene representation for fast and high-quality free-viewpoint rendering. NSVF defines a set of voxel-bounded implicit fields organized in a sparse voxel octree to model local properties in each cell. We progressively learn the underlying voxel structures with a diffentiable ray-marching operation from only a set of posed RGB images. With the sparse voxel octree structure, rendering novel views can be accelerated by skipping the voxels containing no relevant scene content. Our method is over 10 times faster than the state-of-the-art (namely, NeRF (Mildenhall et al., 2020)) at inference time while achieving higher quality results. Furthermore, by utilizing an explicit sparse voxel representation, our method can easily be applied to scene editing and scene composition. We also demonstrate several challenging tasks, including multi-scene learning, free-viewpoint rendering of a moving human, and large-scale scene rendering.">
	<link rel="author" href="https://lingjie0206.github.io/" />


	<!-- Fonts and stuff -->
	<link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800'
		rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" href="css/project.css" media="screen" />
	<link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />
	<script src="js/google-code-prettify/prettify.js"></script>
</head>

<body>
	<div id="content">
		<div id="content-inner">
			<div class="section logos" style="text-align:center">
				<a href="http://www.mpi-inf.mpg.de/home/" target="_blank"><IMG src="./logos/Logo_MPII.png" height="35"
						border="0"></a></td>
				<a href="/index.html" target="_blank"><IMG src="./logos/Logo_gvv.png" height="35" border="0"></a></td>
				<a href="https://ai.facebook.com/" target="_blank"><IMG src="./logos/fair_logo.png" height="35"="0"></a>
				</td>
				<a href="http://nus.edu.sg/" target="_blank"><IMG src="./logos/nus_logo.jpg" height="35"="0"></a></td>
			</div>

			<div class="section head">

				<h1>Neural Sparse Voxel Fields</h1>

				<div class="authors">
					<a href="https://lingjie0206.github.io/" target="_blank">Lingjie Liu*</a><sup> 1</sup>&#160;&#160;
					<a href="http://jiataogu.me/" target="_blank">Jiatao Gu*</a><sup> 2</sup>&#160;&#160;
					Kyaw Zaw Lin<sup> 3</sup>&#160;&#160;
					<a href="https://www.chuatatseng.com/">Tat-Seng Chua</a><sup> 3</sup>&#160;&#160;
					<a href="http://people.mpi-inf.mpg.de/~theobalt/" target="_blank">Christian Theobalt</a><sup>
						1</sup>&#160;&#160;
				</div>

				<div class="affiliations">
					<sup>1</sup><a href="http://www.mpi-inf.mpg.de/home/" target="_blank">MPI Informatics, Saarland
						Informatics Campus</a>&#160;&#160;
					<sup>2</sup><a href="https://ai.facebook.com/" target="_blank">Facebook AI Research</a>&#160;&#160;
					<sup>3</sup><a href="http://nus.edu.sg/" target="_blank">National University of
						Singapore</a>&#160;&#160;
				</div>
				* Joint first authors
				<div class="venue"><a href="https://nips.cc/" target="_blank">NeurIPS 2020 (Spotlight) </a></div>

				<div class="section downloads">
					<!--<h2>Downloads</h2>-->
					<center>
						<ul>
							<li class="grid">
								<div class="griditem">
									<a href="https://arxiv.org/pdf/2007.11571.pdf" target="_blank"
										class="imageLink"><img src="images/pdf.png"></a><br />
									<a href="https://arxiv.org/pdf/2007.11571.pdf">Paper (10 MB)</a>
								</div>
							</li>
							<li class="grid">
								<div class="griditem">
									<a href="https://github.com/facebookresearch/NSVF" target="_blank"
										class="imageLink"><img src="images/data_ico.png"></a><br />
									<a href="https://github.com/facebookresearch/NSVF"> Code & Data </a>

								</div>
							</li>
							<li class="grid">
								<div class="griditem">
									<a href="https://www.dropbox.com/s/sqsnl07fpfhwge2/nips_talk_10m_V3.pptm?dl=0"
										target="_blank" class="imageLink"><img
											src="images/nips_talk_10m_V3.png"></a><br />
									<a href="https://www.dropbox.com/s/sqsnl07fpfhwge2/nips_talk_10m_V3.pptm?dl=0">
										Slides (160 MB)</a>

								</div>
							</li>
						</ul>
					</center>
				</div>
			</div>




			<div class="section abstract">
				<h2>Abstract</h2><br>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="images/pipeline.png" style="width:70%; margin-bottom:20px">

					</div>

				</div>
				<p>
					We introduce Neural Sparse Voxel Fields (NSVF), a new neural scene representation for fast and
					high-quality free-viewpoint rendering. NSVF defines a set of voxel-bounded implicit fields organized
					in a sparse voxel octree to model local properties in each cell. We progressively learn the
					underlying voxel structures with a diffentiable ray-marching operation from only a set of posed RGB
					images. With the sparse voxel octree structure, rendering novel views can be accelerated by skipping
					the voxels containing no relevant scene content. Our method is over 10 times faster than the
					state-of-the-art (namely, NeRF (Mildenhall et al., 2020)) at inference time while achieving higher
					quality results. Furthermore, by utilizing an explicit sparse voxel representation, our method can
					easily be applied to scene editing and scene composition. We also demonstrate several challenging
					tasks, including multi-scene learning, free-viewpoint rendering of a moving human, and large-scale
					scene rendering. </p>
				</p>
			</div>

			<div class="section abstract">
				<h2>Full Video</h2><br>
				<center>
					<!-- <iframe width="640" height="360" src="data/video.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<iframe width="640" height="360" src="https://www.youtube.com/embed/RFqPwH7QFEI" frameborder="0"
						allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
						allowfullscreen></iframe>
					<!--iframe src="./data/video.mp4" allow="autoplay; encrypted-media" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" width="560" height="315" frameborder="0"></iframe-->
					<!--<p style="font-size:11px; text-align:center">
					Download Video: <a href="data/video.mp4" target="_blank">HD</a> (MP4, 111 MB)
				</p>-->
				</center>
			</div>

			<div class="section abstract">
				<h2>Synthetic Results</h2>
				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/synthetic.mp4" type="video/mp4">
					</video>
				</center>
			</div>

			<div class="section abstract">
				<h2>Results of the BlendedMVS Dataset</h2>
				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/blendedmvs.mp4" type="video/mp4">
					</video>
				</center>
			</div>

			<div class="section abstract">
				<h2>Results of the Tanks&Temples Dataset</h2>
				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/tandt.mp4" type="video/mp4">
					</video>
				</center>
			</div>

			<div class="section abstract">
				<h2>Results of Zoom In and Zoom Out</h2>
				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/zoominout.mp4" type="video/mp4">
					</video>
				</center>
			</div>

			<div class="section abstract">
				<h2>Results of a Dynamic Scene</h2>
				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/dynamic.mp4" type="video/mp4">
					</video>
				</center>
			</div>

			<div class="section abstract">
				<h2>Results of ScanNet Scenes</h2>
				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/scannet.mp4" type="video/mp4">
					</video>
				</center>
			</div>

			<div class="section abstract">
				<h2>Results of Scene Editing and Composition</h2>
				<center>
					<!-- <iframe width="640" height="360" src="./mp4/composite3.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/edit1.mp4" type="video/mp4">
					</video>
					<video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
						<source src="mp4/composite3.mp4" type="video/mp4">
					</video>
				</center>
			</div>

			<div class="section abstract">
				<h2>Citation</h2>
				<div class="section bibtex" style="text-align:left; margin-left: 40px; margin-right: 40px">
					<pre>
@article{liu2020neural,
  title={Neural Sparse Voxel Fields},
  author={Liu, Lingjie and Gu, Jiatao and Lin, Kyaw Zaw and Chua, Tat-Seng and Theobalt, Christian},
  journal={NeurIPS},
  year={2020}
}
				</div>
			</div>


			<!--div class="section acknowledgments">
				<h2>Acknowledgments</h2>
				<p>
					This work was funded by the ERC Consolidator Grant 4DRepLy (770784).
				</p>
			</div-->
			
			<!--<div class="section acknowledgments">
				<h2>Useful Links</h2>
				<p>
					<a href="https://www.bilibili.com/video/BV1e7411c7kR?p=52">Talk (in Chinese) at GAMES Webinar</a>
					<a href="http://irc.cs.sdu.edu.cn/2020-summer-school/video/7.18%20pm%20Lingjie%20Liu.mp4
				</p>
			</div-->

			<div class="section">
				<hr class="smooth">
				This page is <a href="http://www.zotero.org" target="_blank">Zotero</a> translator friendly. Page last updated 
				<script type="text/javascript">
					var m = "This page was last updated: " + document.lastModified;
					var p = m.length - 9;
					document.writeln("<left>");
					document.write(m.substring(p, 0) + ".");
					document.writeln("</left>");
				</script>
				<a href="https://www.mpi-inf.mpg.de/imprint/">Imprint</a>. <a href="https://data-protection.mpi-klsb.mpg.de/inf/gvv.mpi-inf.mpg.de/projects/">Data Protection</a>.
			</div>
		</div>
	</div>
</body>
</html>